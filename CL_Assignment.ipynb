{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFdFnJWjT4Hd"
      },
      "source": [
        "# Code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y78YqBWiT8cg"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from torch.utils.data import Subset, TensorDataset, DataLoader\n",
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda:0\"\n",
        "else:\n",
        "  device = \"cpu\"\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUFg-82aTxZw"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPcsQ0HSU7i6"
      },
      "outputs": [],
      "source": [
        "# data\n",
        "\n",
        "def get_random_split_array(num_classes : int, num_tasks: int) -> dict():\n",
        "  \"\"\"\n",
        "  Given a number of classes and a number of tasks,\n",
        "  returns a valid split of the given classes into the given\n",
        "  number of tasks.\n",
        "  \"\"\"\n",
        "\n",
        "  assert num_classes > num_tasks, \"Number of tasks must be equal or smaller than the number of classes\"\n",
        "  assert num_classes > 0, \"Number of classes must be greater than zero\"\n",
        "  assert num_tasks > 0,  \"Number of tasks must be greater than\"\n",
        "\n",
        "  classes = list(range(num_classes))\n",
        "  shuffle(classes)\n",
        "  class_split = {str(i): classes[i*2: (i+1)*2] for i in range(num_tasks)}\n",
        "\n",
        "  return class_split\n",
        "\n",
        "def get_split_dataset(dataset : torch.utils.data.Dataset,\n",
        "                      split: torch.Tensor,\n",
        "                      task_incremental: bool = False) -> dict():\n",
        "  \"\"\"\n",
        "  Accepts a torch dataset and a 2D tensor describing how to split\n",
        "  the original datset in the described tasks. For example, the split\n",
        "  [[3,5],[4,6]] specifies classes 3 and 5 for task 1 and classes 4 and 6\n",
        "  for taks 2. Returns a dictionary containing torch.Subset instances, remapped\n",
        "  if task_incremental is true\n",
        "  \"\"\"\n",
        "  split_dataset = {}\n",
        "\n",
        "  if task_incremental is True:\n",
        "    raise NotImplementedError(\"This method does not support remapping yet\")\n",
        "\n",
        "  for e, current_classes in split.items():\n",
        "      task_indices = np.isin(np.array(dataset.targets), current_classes)\n",
        "      split_dataset[e] = Subset(dataset, np.where(task_indices)[0])\n",
        "  return split_dataset\n",
        "\n",
        "\n",
        "def get_dataloaders(split_dataset : dict(), batch_size: int, shuffle: bool = True) -> dict():\n",
        "  \"\"\"\n",
        "  Given a split dataset (Subset, Task) returns a dictionary containing\n",
        "  all the dataloaders needed\n",
        "  \"\"\"\n",
        "  loaders = {}\n",
        "  for task, data in split_dataset.items():\n",
        "      loaders[task] = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "  return loaders\n",
        "\n",
        "# greedy buffer\n",
        "\n",
        "class GreedyBuffer:\n",
        "    def __init__(self, samples_per_class):\n",
        "        self.samples_per_class = samples_per_class\n",
        "        self.samples = torch.Tensor([])\n",
        "        self.targets = torch.Tensor([])\n",
        "\n",
        "    def store_data(self, loader):\n",
        "        samples, targets = torch.Tensor([]), torch.Tensor([])\n",
        "        for sample, target in loader:\n",
        "            samples = torch.cat((samples, sample))\n",
        "            targets = torch.cat((targets, target))\n",
        "\n",
        "        for label in torch.unique(targets):\n",
        "            greedy_idx = torch.where(targets == label)[0][:self.samples_per_class]\n",
        "            self.samples = torch.cat((self.samples, samples[greedy_idx]))\n",
        "            self.targets = torch.cat((self.targets, targets[greedy_idx]))\n",
        "\n",
        "    def get_data(self):\n",
        "        return self.samples, self.targets.to(torch.int64)\n",
        "\n",
        "    def __len__(self):\n",
        "        assert len(self.samples) == len(self.targets), f\"Incosistent lengths of data tensor: {self.samples.shape}, target tensor: {self.targets.shape}!\"\n",
        "        return len(self.samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LH8VbeUVEbkQ"
      },
      "outputs": [],
      "source": [
        "# metrics\n",
        "\n",
        "def compute_backward_transfer(array : np.array):\n",
        "    \"\"\"\n",
        "    Given a two dimensional array representing the accuracy matrix\n",
        "    T, where T_ij is the model trained on the previous 0...i tasks\n",
        "    and evaluated on the j-th, computes the backward transfer.\n",
        "    \"\"\"\n",
        "    num_tasks = array.shape[0]\n",
        "    diag = np.diag(array)[:-1] # Note, we do not compute backward transfer for the last task!\n",
        "    end_acc = array[:-1, -1]\n",
        "    bwt = np.sum(end_acc - diag)/(num_tasks - 1)\n",
        "    return bwt\n",
        "\n",
        "\n",
        "def compute_forward_transfer(array, b):\n",
        "    \"\"\"\n",
        "    Given a two dimensional array representing the accuracy matrix\n",
        "    T, where T_ij is the model trained on the previous 0...i tasks\n",
        "    and evaluated on the j-th, computes the forward transfer.\n",
        "    \"\"\"\n",
        "    num_tasks = array.shape[0]\n",
        "    sub_diag = np.diag(array, k=-1) # Note, we do not compute forward transfer for the first task!\n",
        "    fwt = np.sum(sub_diag - b[1:])/(num_tasks - 1)\n",
        "    return fwt\n",
        "\n",
        "def compute_average_accuracy(array):\n",
        "    num_tasks = len(array)\n",
        "    avg_acc = np.sum(array[:, -1], axis=0)/num_tasks\n",
        "    return avg_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMOV2JqwEepX"
      },
      "outputs": [],
      "source": [
        "# plotting\n",
        "\n",
        "def dict2array(acc, device):\n",
        "    num_tasks = len(acc)\n",
        "    first_task = list(acc.keys())[0]\n",
        "    sequence_length = len(acc[first_task]) if isinstance(acc[first_task], list) else num_tasks\n",
        "    acc_array = np.zeros((num_tasks, sequence_length))\n",
        "    for task, val in acc.items():\n",
        "        if device != \"cpu\":\n",
        "          val = [x.cpu().numpy() for x in val]\n",
        "\n",
        "        acc_array[int(task), :] = val\n",
        "    return acc_array\n",
        "\n",
        "\n",
        "def plot_accuracy_matrix(array):\n",
        "    num_tasks = array.shape[1]\n",
        "    array = np.round(array, 2)\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(array, vmin=np.min(array), vmax=np.max(array))\n",
        "    for i in range(len(array)):\n",
        "        for j in range(array.shape[1]):\n",
        "            ax.text(j,i, array[i,j], va='center', ha='center', c='w', fontsize=15)\n",
        "    ax.set_yticks(np.arange(num_tasks))\n",
        "    ax.set_ylabel('Number of tasks')\n",
        "    ax.set_xticks(np.arange(num_tasks))\n",
        "    ax.set_xlabel('Tasks finished')\n",
        "    ax.set_title(f\"ACC: {np.mean(array[:, -1]):.3f} -- std {np.std(np.mean(array[:, -1])):.3f}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_acc_over_time(array):\n",
        "    fig, ax = plt.subplots()\n",
        "    for e, acc in enumerate(array):\n",
        "        ax.plot(acc, label=e)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ3RmeBGV272"
      },
      "source": [
        "## Data and split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88xmLEh2V8qn"
      },
      "outputs": [],
      "source": [
        "mean, std = (0.1307), (0.3081)\n",
        "\n",
        "transforms = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize(mean=mean, std=std)\n",
        "        ])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root=\".\", train=True, download=True, transform=transforms) # TODO: add transforms\n",
        "val_dataset = torchvision.datasets.MNIST(root=\".\", train=False, download=True, transform=transforms)\n",
        "\n",
        "# define number of classes and tasks\n",
        "num_classes = len(train_dataset.classes)\n",
        "#@markdown Please ensure that number of tasks is lower (or equal) than the number of classes\n",
        "num_tasks = 5 # @param{type:\"slider\", min:1, max:10, step:1}\n",
        "train_bs = 128 # @param{type:\"integer\", min:2, max:128}\n",
        "val_bs = 128 # @param{type:\"integer\", min:2, max:128}\n",
        "\n",
        "train_split = get_random_split_array(num_classes=num_classes, num_tasks=num_tasks)\n",
        "train_dataset_split = get_split_dataset(train_dataset, train_split)\n",
        "train_loaders = get_dataloaders(train_dataset_split, batch_size=train_bs, shuffle=True)\n",
        "\n",
        "val_dataset_split = get_split_dataset(val_dataset, train_split)\n",
        "val_loaders = get_dataloaders(val_dataset_split, batch_size=val_bs, shuffle=False)\n",
        "\n",
        "print(f\"Using the following splits: \\n training: {train_split} \\n validation: {train_split}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gisBG5pT1AXZ"
      },
      "source": [
        "## Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icIB9C5TxU4P"
      },
      "outputs": [],
      "source": [
        "# MLP\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        hidden_size = args['hidden_size']\n",
        "        self.fc1 = torch.nn.Linear(args['in_size']**2 * args['n_channels'], hidden_size)\n",
        "        self.fc2 = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc4 = torch.nn.Linear(hidden_size, args['num_classes'])\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = input.flatten(start_dim=1)\n",
        "        x = torch.nn.functional.relu(self.fc1(x))\n",
        "        x = torch.nn.functional.relu(self.fc2(x))\n",
        "        x = torch.nn.functional.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Conditional VAE (supports very basic conditioning on class labels)\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim, num_classes):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim + num_classes, hidden_dim)\n",
        "        self.fc1_bis = nn.Linear(hidden_dim, hidden_dim*2)\n",
        "        self.fc2_mean = nn.Linear(hidden_dim*2, latent_dim)\n",
        "        self.fc2_logvar = nn.Linear(hidden_dim*2, latent_dim)\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        x = torch.cat([x, labels], dim=1)\n",
        "        h = torch.relu(self.fc1(x))\n",
        "        h = torch.relu(self.fc1_bis(h))\n",
        "        mean = self.fc2_mean(h)\n",
        "        logvar = self.fc2_logvar(h)\n",
        "        return mean, logvar\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim, hidden_dim, output_dim, num_classes):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim + num_classes, hidden_dim)\n",
        "        self.fc1_bis = nn.Linear(hidden_dim, hidden_dim*2)\n",
        "        self.fc2 = nn.Linear(hidden_dim*2, output_dim)\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        z = torch.cat([z, labels], dim=1)\n",
        "        h = torch.relu(self.fc1(z))\n",
        "        h = torch.relu(self.fc1_bis(h))\n",
        "        x_reconstructed = torch.sigmoid(self.fc2(h))\n",
        "        return x_reconstructed\n",
        "\n",
        "class CVAE(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(CVAE, self).__init__()\n",
        "\n",
        "        input_dim = args[\"input_dim\"]\n",
        "        hidden_dim = args[\"hidden_dim\"]\n",
        "        latent_dim = args[\"latent_dim\"]\n",
        "        num_classes = args[\"num_classes\"]\n",
        "\n",
        "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim, num_classes)\n",
        "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim, num_classes)\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mean + eps * std\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        mean, logvar = self.encoder(x, labels)\n",
        "        z = self.reparameterize(mean, logvar)\n",
        "        x_reconstructed = self.decoder(z, labels)\n",
        "        return x_reconstructed, mean, logvar\n",
        "\n",
        "    def sample(self, num_samples, latent_dim, class_label):\n",
        "        z = torch.randn(num_samples, latent_dim).to('cuda')\n",
        "        labels = torch.zeros(num_samples, self.num_classes).to('cuda')\n",
        "        labels[:, class_label] = 1\n",
        "        samples = self.decoder(z, labels)\n",
        "        return samples\n",
        "\n",
        "def vae_loss(x_reconstructed, x, mean, logvar):\n",
        "    # Reconstruction loss\n",
        "    reconstruction_loss = nn.functional.mse_loss(x_reconstructed, x, reduction=\"sum\")\n",
        "\n",
        "    # KL divergence loss\n",
        "    kl_divergence = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
        "\n",
        "    # Total loss\n",
        "    return reconstruction_loss + kl_divergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoYkSIkS1B7D"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "# agents\n",
        "class Agent:\n",
        "  \"\"\"\n",
        "  Super class defining a CL agent that\n",
        "  implements the basic utilities. Each subclass\n",
        "  must implement its own train and validation.\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "               criterion: torch.nn.modules.loss._Loss,\n",
        "               tasks: list,\n",
        "               training_args: dict(),\n",
        "               model_args: dict()):\n",
        "    self.criterion = criterion\n",
        "    self.tasks = tasks\n",
        "    self.training_args = training_args\n",
        "    self.model_args = model_args\n",
        "    self.model = MLP(model_args[\"MLP\"]).to(device)\n",
        "    self.optimizer = None\n",
        "\n",
        "    if self.training_args[\"use_buffer\"] > 0:\n",
        "      self.buffer = GreedyBuffer(samples_per_class=self.training_args[\"use_buffer\"])\n",
        "    else:\n",
        "      self.buffer = None\n",
        "\n",
        "    if self.training_args[\"generative\"] > 0:\n",
        "      self.generative_replay = True\n",
        "      self.ConditionalVAE = CVAE(self.model_args[\"CVAE\"]).to(device)\n",
        "    else:\n",
        "      self.generative_replay = False\n",
        "      self.ConditionalVAE = None\n",
        "\n",
        "    # Note that tasks should be a list of integers for ease of use\n",
        "    self.acc_dict = {key: [] for key in tasks} #dictionary storing the accuracy of the model on all tasks on current iteration\n",
        "    self.acc_end_dict = {key: [] for key in tasks} #dictionary storing the accuracy of the model on all tasks so far, measured at the end\n",
        "\n",
        "  def reset_accuracy(self):\n",
        "    self.acc_dict = {key: [] for key in self.tasks}\n",
        "    self.acc_end_dict = {key: [] for key in self.tasks}\n",
        "\n",
        "  def train_VAE(self, loader, current_task):\n",
        "    \"\"\"\n",
        "    Starts or continues to train the CVAE to act as\n",
        "    a replay buffer. Returns a buffer with samples\n",
        "    generated from the classes seen so far.\n",
        "    \"\"\"\n",
        "\n",
        "    #training\n",
        "    #NOTE: should optimizer be created every time? dunno\n",
        "    optimizer = torch.optim.AdamW(self.ConditionalVAE.parameters(), lr=1e-3)\n",
        "\n",
        "    self.ConditionalVAE.train()\n",
        "    for epoch in range(self.model_args[\"CVAE\"][\"training_epochs\"][current_task]):\n",
        "        total_loss = 0\n",
        "        for batch_idx, (data, labels) in enumerate(loader):\n",
        "            data = data.view(-1, self.model_args[\"CVAE\"][\"input_dim\"]).to(device)\n",
        "            labels = torch.nn.functional.one_hot(labels, num_classes).float().to(device)\n",
        "            optimizer.zero_grad()\n",
        "            x_reconstructed, mean, logvar = self.ConditionalVAE(data, labels)\n",
        "            loss = vae_loss(x_reconstructed, data, mean, logvar)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(loader.dataset)\n",
        "        if epoch % 5 == 0:\n",
        "          print(f'Epoch [{epoch+1}/{self.model_args[\"CVAE\"][\"training_epochs\"][current_task]}], Loss: {avg_loss:.4f}')\n",
        "\n",
        "    #sampling\n",
        "    sampled_dataset = torch.tensor([]).to(device)\n",
        "    sampled_labels = torch.tensor([]).to(device)\n",
        "    num_samples = self.training_args[\"generative\"]\n",
        "    latent_dim = self.model_args[\"CVAE\"][\"latent_dim\"]\n",
        "    available_tasks = list(range(int(current_task)+1))\n",
        "    available_labels = []\n",
        "\n",
        "    for task in available_tasks:\n",
        "      # NOTE/TODO: the split should have been passed as an arg, i know\n",
        "      # this is bad code, apologies\n",
        "      available_labels.append(train_split[str(task)][0])\n",
        "      available_labels.append(train_split[str(task)][1])\n",
        "\n",
        "    # generate all samples\n",
        "    with torch.no_grad():\n",
        "        for label in available_labels:\n",
        "          # generate samples for each class seen so far\n",
        "          samples = self.ConditionalVAE.sample(num_samples, latent_dim, label)\n",
        "\n",
        "          # Reshape the samples before adding to dataset\n",
        "          samples = samples.view(num_samples, 1, 28, 28)\n",
        "          sampled_dataset = torch.cat((sampled_dataset, samples), dim=0)\n",
        "\n",
        "          labels = torch.tensor([int(label)]).repeat(num_samples)\n",
        "          labels = labels.to(device)\n",
        "          sampled_labels = torch.cat((sampled_labels, labels), dim=0)\n",
        "\n",
        "    return sampled_dataset, sampled_labels.to(torch.int64)\n",
        "\n",
        "class CIA_Agent(Agent):\n",
        "  def __init__(self, criterion, tasks, training_args, model_args):\n",
        "    super().__init__(criterion, tasks, training_args, model_args)\n",
        "    #add additional CI init steps here\n",
        "\n",
        "  def _shared_step(self, loader : torch.utils.data.DataLoader, val_loaders: dict() = None, train: bool = True):\n",
        "    epoch_loss, total, correct = 0, 0, 0\n",
        "\n",
        "    for e, (X, y) in enumerate(loader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      output = self.model(X)\n",
        "      loss = self.criterion(output, y)\n",
        "\n",
        "      if train:\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "      correct += torch.sum(torch.topk(output, axis=1, k=1)[1].squeeze(1) == y)\n",
        "      total += len(X)\n",
        "\n",
        "      # mid epoch validation\n",
        "      # not executed when the validation shared step is called\n",
        "      if e % 50 == 0 and train:\n",
        "        self.validate(val_loaders, end_of_epoch = False)\n",
        "\n",
        "    # I guess e is still visible after the for, uh?\n",
        "    return epoch_loss / e, total, correct\n",
        "\n",
        "  def train(self, train_loaders : dict(), val_loaders : dict()):\n",
        "    for task, loader in train_loaders.items():\n",
        "      print(f\"Currently on task {task} \\n\")\n",
        "      print(\"Resetting model and optimizer \\n\")\n",
        "      self.model = MLP(self.model_args[\"MLP\"]).to(device)\n",
        "      self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
        "\n",
        "      if self.buffer is not None:\n",
        "        self.buffer.store_data(loader)\n",
        "        print(f\"Buffer stores {len(self.buffer)} samples\")\n",
        "        samples, targets = self.buffer.get_data()\n",
        "        greedy_dataset = TensorDataset(samples, targets)\n",
        "        #overwrite loader with new greedy dataset, consisting only of greedily accumulated samples\n",
        "        greedy_loader = DataLoader(greedy_dataset, batch_size=loader.batch_size, shuffle=True)\n",
        "        loader = greedy_loader\n",
        "      elif self.generative_replay:\n",
        "        #first train VAE\n",
        "        print(\"Training VAE \\n\")\n",
        "        gen_dataset, gen_labels = self.train_VAE(loader, task)\n",
        "        gen_data = TensorDataset(gen_dataset, gen_labels)\n",
        "        #overwrite loader with the samples generated by the CVAE\n",
        "        gen_loader = DataLoader(gen_data, batch_size=loader.batch_size, shuffle=True)\n",
        "        loader = gen_loader\n",
        "        print(f\"Using VAE samples, new size {gen_dataset.shape[0]}, labels {torch.unique(gen_labels)}\")\n",
        "\n",
        "      print(\"Training MLP on samples\")\n",
        "      for epoch in range(self.training_args['epochs'][task]):\n",
        "        epoch_loss, total, correct = self._shared_step(loader, val_loaders, train=True)\n",
        "        print(f\"Epoch {epoch}: Loss {epoch_loss:.3f} Acc: {correct/total:.3f}\")\n",
        "\n",
        "      print(f\"Evaluating after task {task} \\n\")\n",
        "      self.validate(val_loaders, end_of_epoch=True)\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def validate(self, val_loaders, end_of_epoch=False):\n",
        "      self.model.eval()\n",
        "\n",
        "      for task, loader in val_loaders.items():\n",
        "        _, total, correct = self._shared_step(loader, None, train=False)\n",
        "        self.acc_dict[task].append(correct/total)\n",
        "\n",
        "        if end_of_epoch:\n",
        "          (self.acc_end_dict[task]).append(correct/total)\n",
        "\n",
        "      self.model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4yOpmCPwnsw"
      },
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNQThw97wpih"
      },
      "outputs": [],
      "source": [
        "# TODO: convert to omegadict\n",
        "# train args\n",
        "training_args = {\n",
        "    \"epochs\": {\n",
        "        \"0\": 10,\n",
        "        \"1\": 10,\n",
        "        \"2\": 10,\n",
        "        \"3\": 10,\n",
        "        \"4\": 10,\n",
        "        },\n",
        "    \"use_buffer\": 0, #if set to anything more than 0, will use a greedy buffer for training\n",
        "    \"generative\": 300, #if set to anything more than 0, will use a VAE generated buffer for training\n",
        "}\n",
        "\n",
        "# model args\n",
        "model_args = {\n",
        "    \"MLP\" : {\n",
        "      'in_size': 28,\n",
        "      'n_channels': 1,\n",
        "      'hidden_size': 50,\n",
        "      'num_classes' : num_classes\n",
        "    },\n",
        "    \"CVAE\" : {\n",
        "        \"input_dim\" : 28 * 28,\n",
        "        \"hidden_dim\" : 2048, #1024\n",
        "        \"latent_dim\" : 256, # 128\n",
        "        \"num_classes\" : 10,\n",
        "        \"training_epochs\": {\n",
        "            \"0\": 30,\n",
        "            \"1\": 30,\n",
        "            \"2\": 30,\n",
        "            \"3\": 30,\n",
        "            \"4\": 30,\n",
        "        },\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hnf6QbvTDdgg"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "tasks = list(train_split.keys())\n",
        "\n",
        "# Create the agent & initialize the network\n",
        "agent = CIA_Agent(criterion=criterion, tasks=tasks, training_args=training_args, model_args=model_args)\n",
        "\n",
        "# Check & save (for the FWT metric) the accuracy of randomly initialized model\n",
        "agent.validate(val_loaders)\n",
        "random_model_acc = [i[0] for i in agent.acc_dict.values()]\n",
        "agent.reset_accuracy()\n",
        "\n",
        "# Train the agent on the whole sequence of tasks\n",
        "agent.train(train_loaders, val_loaders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qVr5mUaOnjN"
      },
      "outputs": [],
      "source": [
        "# Get accuracy of the agent at the end of each task\n",
        "acc_at_end_arr = dict2array(agent.acc_end_dict, device=device)\n",
        "plot_accuracy_matrix(acc_at_end_arr)\n",
        "\n",
        "# Get intermediate accuracy\n",
        "acc_arr = dict2array(agent.acc_dict, device=device)\n",
        "plot_acc_over_time(acc_arr)\n",
        "\n",
        "# move random model acc to cpu\n",
        "if random_model_acc[0].device != \"cpu\":\n",
        "  random_model_acc = [x.cpu().numpy() for x in random_model_acc]\n",
        "\n",
        "print(f\"The average accuracy at the end of sequence is: {compute_average_accuracy(acc_at_end_arr):.3f}\")\n",
        "print(f\"BWT:'{compute_backward_transfer(acc_at_end_arr):.3f}'\")\n",
        "print(f\"FWT:'{compute_forward_transfer(acc_at_end_arr, random_model_acc):.3f}'\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}